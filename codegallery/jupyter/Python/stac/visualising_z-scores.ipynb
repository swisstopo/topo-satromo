{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <span style=\"color:#336699\">Visualising Z-Scores</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "<div style=\"text-align: left;\">\n",
    "    <a href=\"https://nbviewer.org/github/swisstopo/topo-satromo/blob/dev-20241209/codegallery/jupyter/Python/stac/stac-introduction.ipynb\"><img src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\" align=\"center\"/></a>\n",
    "</div>\n",
    "   \n",
    "<br/>\n",
    "\n",
    "<b>Abstract.</b> This Jupyter Notebook visualises z-scores and explains what they tell you.\n",
    "\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score\n",
    "Z-scores describe how far from the mean a certain value is and thus indicate how \"normal\" or \"rare\" it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x values from -4 to 4 standard deviations\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate the standard normal distribution (mean=0, std=1)\n",
    "y = stats.norm.pdf(x, 0, 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Define the color gradient\n",
    "colors = ['#7d6608', '#d4ac0d', '#f7dc6f', '#f5f5f5', '#7dcea0', '#229954', '#145a32']\n",
    "# positions = [-3, -2, -1, 0, 1, 2, 3]  # Corresponding x positions for color transitions\n",
    "\n",
    "# Create custom colormap\n",
    "cmap = LinearSegmentedColormap.from_list('custom', list(zip(np.linspace(0, 1, len(colors)), colors)))\n",
    "\n",
    "# Create the gradient fill\n",
    "for i in range(len(x)-1):\n",
    "    # Normalize x value to 0-1 range for colormap (mapping -4 to 4 range to 0-1)\n",
    "    norm_x = (x[i] + 4) / 8  # Convert -4 to 4 range to 0 to 1 range\n",
    "    color = cmap(norm_x)\n",
    "    \n",
    "    # Fill small segment under curve\n",
    "    plt.fill_between([x[i], x[i+1]], [0, 0], [y[i], y[i+1]], color=color, alpha=0.7)\n",
    "\n",
    "\n",
    "plt.plot(x, y, 'k-', linewidth=2, label='Standard Normal Distribution')\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel('Z-Score', fontsize=14)\n",
    "plt.ylabel('Probability Density', fontsize=14)\n",
    "\n",
    "# Remove y-axis tick labels\n",
    "plt.yticks([])\n",
    "\n",
    "# Set x-axis ticks at standard deviation intervals\n",
    "plt.xticks(np.arange(-4, 5), ['-4', '-3', '-2', '-1', '0', '1', '2', '3', '4'], fontsize=14)\n",
    "\n",
    "# Add vertical lines from x-axis to curve at key z-scores\n",
    "for i in range(-3, 4):\n",
    "    y_at_i = stats.norm.pdf(i, 0, 1)  # Get y-value on curve at x=i\n",
    "    plt.plot([i, i], [0, y_at_i], color='gray', linestyle='-', alpha=0.7, linewidth=1)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-0.29, 0.42)  # Extended bottom to accommodate arrows\n",
    "\n",
    "# Create custom arrows for axes\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Hide the part of y-axis below zero\n",
    "ax.spines['left'].set_bounds(0, 0.42)  # Only show y-axis from 0 to top\n",
    "ax.yaxis.set_label_coords(0.5, 0.7)  # Position y-label in middle of positive range\n",
    "\n",
    "# Add horizontal double-headed arrows with percentages\n",
    "arrow_y1 = -0.15\n",
    "arrow_y2 = -0.22\n",
    "arrow_y3 = -0.29\n",
    "\n",
    "# 68% arrow (±1σ)\n",
    "ax.annotate('', xy=(1, arrow_y1), xytext=(-1, arrow_y1),\n",
    "            arrowprops=dict(arrowstyle='<->', color='black', lw=1))\n",
    "ax.text(0, arrow_y1 + 0.01, '68%', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# 95% arrow (±2σ)\n",
    "ax.annotate('', xy=(2, arrow_y2), xytext=(-2, arrow_y2),\n",
    "            arrowprops=dict(arrowstyle='<->', color='black', lw=1))\n",
    "ax.text(0, arrow_y2 + 0.01, '95%', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# 99.7% arrow (±3σ)\n",
    "ax.annotate('', xy=(3, arrow_y3), xytext=(-3, arrow_y3),\n",
    "            arrowprops=dict(arrowstyle='<->', color='black', lw=1))\n",
    "ax.text(0, arrow_y3 + 0.01, '99.7%', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Add some statistical information\n",
    "print(\"Key properties of the standard normal distribution:\")\n",
    "print(f\"Mean (μ): 0\")\n",
    "print(f\"Standard deviation (σ): 1\")\n",
    "print(f\"68% of data falls within ±1σ: [{-1:.1f}, {1:.1f}]\")\n",
    "print(f\"95% of data falls within ±2σ: [{-2:.1f}, {2:.1f}]\")\n",
    "print(f\"99.7% of data falls within ±3σ: [{-3:.1f}, {3:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real values from the GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from pydrive.auth import GoogleAuth\n",
    "from oauth2client.service_account import ServiceAccountCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEE credentials\n",
    "config = r'D:\\Users\\joan-sturm-w1\\Documents\\GitHub\\topo-satromo\\secrets\\geetest-credentials-int.secret'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Google Earth Engine (GEE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE initialization successful\n"
     ]
    }
   ],
   "source": [
    "def initialize_gee_and_drive():\n",
    "    \"\"\"\n",
    "    Initializes and authenticates Google Earth Engine (GEE) and Google Drive APIs using service account credentials.\n",
    "    \n",
    "    This function:\n",
    "    1. Sets up authentication scopes for Google Drive\n",
    "    2. Reads service account key file from the config path\n",
    "    3. Authenticates with Google Drive using the service account credentials\n",
    "    4. Initializes Google Earth Engine with the same credentials\n",
    "    5. Performs a test query to verify GEE initialization was successful\n",
    "    \n",
    "    Requirements:\n",
    "        - PyDrive (for Google Drive authentication)\n",
    "        - Earth Engine Python API (ee)\n",
    "        - oauth2client (for ServiceAccountCredentials)\n",
    "        - Valid service account key file path in config variable\n",
    "    \n",
    "    Returns:\n",
    "        None. Prints confirmation message if initialization was successful or failure message otherwise.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the service account key file cannot be found\n",
    "        JSONDecodeError: If the service account key file is not valid JSON\n",
    "        EEException: If Earth Engine initialization fails\n",
    "    \"\"\"\n",
    "    # Set scopes for Google Drive\n",
    "    scopes = [\"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    # Initialize GEE and authenticate using the service account key file\n",
    "\n",
    "    # Read the service account key file\n",
    "    with open(config, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Authenticate with Google using the service account key file\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.service_account_file = config\n",
    "    gauth.service_account_email = data[\"client_email\"]\n",
    "    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "        gauth.service_account_file, scopes=scopes\n",
    "    )\n",
    "\n",
    "    # Initialize Google Earth Engine\n",
    "    credentials = ee.ServiceAccountCredentials(\n",
    "        gauth.service_account_email, gauth.service_account_file\n",
    "    )\n",
    "    ee.Initialize(credentials)\n",
    "\n",
    "    # Test if GEE initialization is successful\n",
    "    image = ee.Image(\"NASA/NASADEM_HGT/001\")\n",
    "    title = image.get(\"title\").getInfo()\n",
    "\n",
    "    if title == \"NASADEM: NASA NASADEM Digital Elevation 30m\":\n",
    "        print(\"GEE initialization successful\")\n",
    "    else:\n",
    "        print(\"GEE initialization FAILED\")\n",
    "\n",
    "# Authenticate with GEE and GDRIVE\n",
    "initialize_gee_and_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "### Defining collections, time and other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the warn regions feature and VHI image collections\n",
    "regions = ee.FeatureCollection('projects/satromo-prod/assets/res/warnregionen_vhi_2056')\n",
    "ndvi_ref_col = ee.ImageCollection('projects/satromo-prod/assets/col/1991-2020_NDVI_SWISS')\n",
    "s2_col = ee.ImageCollection('projects/satromo-prod/assets/col/S2_SR_HARMONIZED_SWISS')\n",
    "\n",
    "# Set the time period (two months ideally to match swissEO NDVIz)\n",
    "startDate = '2023-08-01'\n",
    "endDate = '2023-10-01' # first day outside of desired time period\n",
    "# Get day of the year for both\n",
    "ee_date = ee.Date(startDate)\n",
    "start_doy = int(ee_date.format('D').getInfo())\n",
    "ee_date = ee.Date(endDate)\n",
    "end_doy = int(ee_date.format('D').getInfo())\n",
    "# print(start_doy, end_doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using forest-only geometry for sampling\n"
     ]
    }
   ],
   "source": [
    "# Defining the region of interest (ROI)\n",
    "\n",
    "# AOI -> chose specific warn region or ...\n",
    "# region_nr = 34 #[31-68]  \n",
    "# region_feature = regions.filter(ee.Filter.eq('REGION_NR', region_nr)).first()\n",
    "# # Get the region geometry\n",
    "# aoi = region_feature.geometry()\n",
    "\n",
    "# AOI -> ... a region by its coordinates\n",
    "# aoi = ee.Geometry.Rectangle([8.06, 47.14, 8.72, 47.18]) # Raten ZG/SZ\n",
    "# aoi = ee.Geometry.Rectangle([6.40, 46.47, 6.81, 46.61]) # Lausanne VD\n",
    "aoi = ee.Geometry.Rectangle([7.37, 46.95, 7.44, 46.97]) # Bremgartenwald, Bern\n",
    "\n",
    "# Vegetation type: FOREST or ...\n",
    "vegmask = ee.Image('projects/satromo-prod/assets/res/ch_bafu_lebensraumkarte_mask_forest_epsg32632')\n",
    "# ... all vegetation\n",
    "# vegmask = ee.Image('projects/satromo-prod/assets/res/ch_bafu_lebensraumkarte_mask_vegetation_epsg32632')\n",
    "\n",
    "# Combining aoi and vegetation mask\n",
    "roi = vegmask.clip(aoi)\n",
    "\n",
    "# Extract forest-only geometry \n",
    "try:\n",
    "    # Convert the forest mask to vector geometry for sampling\n",
    "    forest_geometry = roi.select('b1').gte(1).reduceToVectors(\n",
    "        geometry=aoi,\n",
    "        scale=30,\n",
    "        maxPixels=1e9,\n",
    "        geometryType='polygon'\n",
    "    ).geometry()\n",
    "    sampling_geometry = forest_geometry\n",
    "    print(\"Using forest-only geometry for sampling\")\n",
    "except:\n",
    "    # Fallback to AOI if vector conversion fails\n",
    "    sampling_geometry = aoi\n",
    "    print(\"Using full AOI geometry for sampling (fallback)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If roi is an image mask\n",
    "ndvi_ref_col_masked = ndvi_ref_col.map(lambda img: img.updateMask(roi))\n",
    "s2_col_masked = s2_col.map(lambda img: img.updateMask(roi))\n",
    "\n",
    "# If aoi is a geometry\n",
    "# ndvi_ref_col_masked = ndvi_ref_col.map(lambda img: img.clip(aoi))\n",
    "# s2_col_masked = s2_col.map(lambda img: img.clip(aoi))\n",
    "\n",
    "# Scale the reference values appropriately\n",
    "def scale_reference(image):\n",
    "    \"\"\"\n",
    "    Scales the reference image to 0-1 range.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): The input reference image to scale.\n",
    "        \n",
    "    Returns:\n",
    "        ee.Image: The scaled reference image.\n",
    "    \"\"\"\n",
    "    # Get scale and offset from image properties\n",
    "    scale = ee.Number(image.get('scale'))\n",
    "    offset = ee.Number(image.get('offset'))\n",
    "    \n",
    "    # Scale the 'median' band\n",
    "    scaled_band = image.select('median').subtract(offset).divide(scale)\n",
    "    \n",
    "    return scaled_band.copyProperties(image, image.propertyNames())\n",
    "\n",
    "# Scale the NDVI reference collection\n",
    "ndvi_ref_col_scaled = ndvi_ref_col_masked.map(scale_reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_to_dataframe_efficient(image_collection, roi_geometry):\n",
    "    \"\"\"\n",
    "    Efficient extraction using reduceRegions\n",
    "    Each image becomes a column, each valid pixel becomes a row\n",
    "    \"\"\"\n",
    "    \n",
    "    def extract_image_values(image):\n",
    "        # Reduce the image to get pixel values within ROI\n",
    "        values = image.select(['medain']).reduceRegion(\n",
    "            reducer=ee.Reducer.toList(),\n",
    "            geometry=roi_geometry,\n",
    "            scale=30,  # Adjust your scale\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        \n",
    "        # Get DOY or image identifier\n",
    "        doy = image.get('doy')\n",
    "        \n",
    "        return ee.Feature(None, {\n",
    "            'doy': doy,\n",
    "            'values': values.get('median')\n",
    "        })\n",
    "    \n",
    "    # Map over the collection\n",
    "    value_collection = image_collection.map(extract_image_values)\n",
    "    \n",
    "    # Get the results\n",
    "    results = value_collection.getInfo()['features']\n",
    "    \n",
    "    # Build DataFrame\n",
    "    data_dict = {}\n",
    "    for feature in results:\n",
    "        doy = feature['properties']['doy']\n",
    "        values = feature['properties']['values']\n",
    "        data_dict[f'doy_{doy}'] = values\n",
    "    \n",
    "    # Handle different lengths\n",
    "    max_length = max(len(v) for v in data_dict.values() if v is not None)\n",
    "    for key in data_dict:\n",
    "        if data_dict[key] is None:\n",
    "            data_dict[key] = []\n",
    "        data_dict[key].extend([None] * (max_length - len(data_dict[key])))\n",
    "    \n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df\n",
    "\n",
    "# Extract to DataFrame\n",
    "df = extract_to_dataframe_efficient(ndvi_ref_col_scaled, aoi)\n",
    "\n",
    "# Display info\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median NDVI for swissEO S2-SR image collection\n",
    "def loadNdviCurrentData(image):\n",
    "    \"\"\"\n",
    "    Loads the current NDVI data from Sentinel-2 imagery.\n",
    "\n",
    "    Args:\n",
    "        image (ee.ImageCollection): Sentinel-2 image collection.\n",
    "\n",
    "    Returns:\n",
    "        ee.Image: Combined image with median NDVI and pixel count bands\n",
    "    \"\"\"\n",
    "    # Apply the cloud and terrain shadow mask within the S2 image collection\n",
    "    def applyMasks(image):\n",
    "        image = image.updateMask(image.select('terrainShadowMask').lt(65))\n",
    "        image = image.updateMask(image.select('cloudAndCloudShadowMask').eq(0))\n",
    "        image = image.updateMask(image.select('ndsi').lt(0.43))\n",
    "        return image\n",
    "    S2_col_masked = image.map(applyMasks)\n",
    "\n",
    "    # Calculate NDVI for each image\n",
    "    def calculate_ndvi(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('ndvi')\n",
    "        return ndvi\n",
    "    \n",
    "    ndvi_col = S2_col_masked.map(calculate_ndvi)\n",
    "    \n",
    "    # Calculate median NDVI\n",
    "    ndvi_median = ndvi_col.median().rename('median')\n",
    "    \n",
    "    return ndvi_median\n",
    "\n",
    "# Calculate NDVI for the current S2 collection\n",
    "ndvi_s2_col_masked = loadNdviCurrentData(s2_col_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and add z-score band to image collection\n",
    "def add_zscore_band(image):\n",
    "    \"\"\"\n",
    "    Add a z-score band to each image.\n",
    "    \n",
    "    Args:\n",
    "        collection: ee.ImageCollection - The NDVI reference collection with statistics\n",
    "    \n",
    "    Returns:\n",
    "        ee.ImageCollection - Collection with z-score band added to each image\n",
    "    \"\"\"    \n",
    "    # Calculate mean and std of the median band across the entire collection \n",
    "    # within the forest stand area\n",
    "    ndvi = image.select('median')\n",
    "    \n",
    "    # Calculate mean and std of the ndvi values\n",
    "    mean = ndvi.reduceRegion(ee.Reducer.mean())\n",
    "    std = ndvi.reduceRegion(ee.Reducer.stdDev())\n",
    "    \n",
    "    # Calculate z-score: (median - mean) / std\n",
    "    zscore = ndvi.subtract(ee.Number(mean)).divide(ee.Number(std))\n",
    "    zscore = zscore.rename('zscore')\n",
    "    \n",
    "    return image.addBands(zscore)\n",
    "\n",
    "# Map the z-score calculation over the entire collection\n",
    "ndvi_ref_col_z = ndvi_ref_col_masked.map(add_zscore_band)\n",
    "ndvi_s2_col_z = add_zscore_band(ndvi_s2_col_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of pixels with stratified sampling\n",
    "def extract_ndvi_data_sampled(image_collection, max_pixels_per_image=5000, scale=100):\n",
    "    \"\"\"\n",
    "    Extract NDVI data using regular sampling with larger scale to avoid pixel limits\n",
    "    \"\"\"\n",
    "    def sample_image(image):\n",
    "        # Add DOY to the image\n",
    "        doy = ee.Number(image.get('system:index'))\n",
    "        \n",
    "        # Use regular sample with larger scale to reduce pixel count\n",
    "        sample = image.select(['median', 'z_score']).sample(\n",
    "            region=image.geometry(),\n",
    "            scale=scale,  # Larger scale = fewer pixels to process\n",
    "            numPixels=max_pixels_per_image,\n",
    "            geometries=False\n",
    "        )\n",
    "        \n",
    "        # Add DOY to each sample\n",
    "        def add_doy(feature):\n",
    "            return feature.set('doy', doy)\n",
    "        \n",
    "        return sample.map(add_doy)\n",
    "    \n",
    "    # Map over collection and flatten\n",
    "    samples = image_collection.map(sample_image).flatten()\n",
    "    \n",
    "    # Get sample data\n",
    "    sample_data = samples.getInfo()['features']\n",
    "    \n",
    "    data = []\n",
    "    for feature in sample_data:\n",
    "        props = feature['properties']\n",
    "        if props['median'] is not None and props['z_score'] is not None:\n",
    "            data.append({\n",
    "                'doy': int(props['doy']),\n",
    "                'median': props['median'],\n",
    "                'z_score': props['z_score']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = extract_ndvi_data_sampled(ndvi_ref_col_z, max_pixels_per_image=5000, scale=100)\n",
    "print(f\"Extracted {len(df)} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "def create_ndvi_plot(df):\n",
    "    \"\"\"\n",
    "    Create the NDVI plot with z-score coloring\n",
    "    \"\"\"\n",
    "    # Define the color mapping for z-scores\n",
    "    z_colors = {\n",
    "        -5: '#7d6608',\n",
    "        -3: '#d4ac0d', \n",
    "        -1: '#f7dc6f',\n",
    "        0: '#f5f5f5',\n",
    "        1: '#7dcea0',\n",
    "        3: '#229954',\n",
    "        5: '#145a32'\n",
    "    }\n",
    "    \n",
    "    # Create a custom colormap\n",
    "    z_values = sorted(z_colors.keys())\n",
    "    colors = [z_colors[z] for z in z_values]\n",
    "    n_bins = 100\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list('z_score', colors, N=n_bins)\n",
    "    \n",
    "    # Convert DOY to dates for better x-axis labels\n",
    "    def doy_to_date(doy, year=2020):  # Using 2020 as a reference year (leap year)\n",
    "        return datetime(year, 1, 1) + timedelta(days=doy - 1)\n",
    "    \n",
    "    df['date'] = df['doy'].apply(doy_to_date)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    scatter = ax.scatter(df['date'], df['median'], \n",
    "                        c=df['z_score'], \n",
    "                        cmap=cmap, \n",
    "                        vmin=-5, vmax=5,\n",
    "                        alpha=0.6, \n",
    "                        s=20)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Month', fontsize=12)\n",
    "    ax.set_ylabel('NDVI Median Values', fontsize=12)\n",
    "    ax.set_title('NDVI Time Series with Z-Score Coloring', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Format x-axis to show months\n",
    "    import matplotlib.dates as mdates\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "    ax.xaxis.set_minor_locator(mdates.WeekdayLocator())\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label('Z-Score', fontsize=12)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tight layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Create and display the plot\n",
    "fig, ax = create_ndvi_plot(df)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "techtalk.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
